# tests/catalyst/pipeline/prompt_engineering/test_prompt_generator.py

import pytest
import json
from pathlib import Path

from catalyst.models.trend_report import FashionTrendReport
from catalyst.pipeline.prompt_engineering.prompt_generator import (
    PromptGenerator,
    CreativeStyleGuideModel,
    DEFAULT_STYLE_GUIDE,
)

# --- START: THE FIX (Step 1) ---
# Import the specific exception the code is designed to catch.
from catalyst.resilience import MaxRetriesExceededError

# --- END: THE FIX (Step 1) ---

# This is the path to the function we will mock in the tests.
INVOKER_PATH = (
    "catalyst.pipeline.prompt_engineering.prompt_generator.invoke_with_resilience"
)


@pytest.fixture
def full_trend_report() -> FashionTrendReport:
    """
    Loads a realistic, complete trend report from the tests/fixtures directory.
    """
    report_path = (
        Path(__file__).parent.parent.parent / "fixtures" / "expected_final_report.json"
    )
    with open(report_path, "r") as f:
        data = json.load(f)
    return FashionTrendReport.model_validate(data)


@pytest.mark.asyncio
async def test_prompt_generator_happy_path(mocker, full_trend_report):
    """
    Tests the main success scenario: the style guide is generated by the AI,
    and all prompts are correctly formatted based on the input report.
    """
    # ARRANGE
    mock_invoker = mocker.patch(INVOKER_PATH)
    mock_style_guide = CreativeStyleGuideModel(
        art_direction="A mock art direction.",
        negative_style_keywords="mock, fake, unreal",
    )
    mock_invoker.return_value = mock_style_guide

    prompt_generator = PromptGenerator(report=full_trend_report)

    # ACT
    generated_prompts = await prompt_generator.generate_prompts()

    # ASSERT
    mock_invoker.assert_called_once()
    assert isinstance(generated_prompts, dict)
    assert len(generated_prompts) == len(full_trend_report.detailed_key_pieces)
    assert "The Heritage Drape Blazer" in generated_prompts

    first_piece_prompts = generated_prompts["The Heritage Drape Blazer"]
    assert "mood_board" in first_piece_prompts
    assert "final_garment" in first_piece_prompts

    final_garment_prompt = first_piece_prompts["final_garment"]
    assert "A mock art direction." in final_garment_prompt
    assert "The Heritage Drape Blazer" in final_garment_prompt
    assert "Deep Navy and Charcoal Grey" in final_garment_prompt
    assert "Within a hushed Savile Row atelier" in final_garment_prompt
    assert "Avoid mock, fake, unreal" in final_garment_prompt


@pytest.mark.asyncio
async def test_prompt_generator_uses_fallback_on_ai_failure(mocker, full_trend_report):
    """
    Tests the resilience scenario: if the AI call for the style guide fails,
    the generator should use the hardcoded DEFAULT_STYLE_GUIDE and still
    produce valid prompts.
    """
    # ARRANGE
    mock_invoker = mocker.patch(INVOKER_PATH)
    # --- START: THE FIX (Step 2) ---
    # Raise the specific, expected exception. The MaxRetriesExceededError
    # requires a `last_exception` argument, so we provide a simple one.
    mock_invoker.side_effect = MaxRetriesExceededError(
        last_exception=ValueError("Simulated AI failure")
    )
    # --- END: THE FIX (Step 2) ---

    prompt_generator = PromptGenerator(report=full_trend_report)

    # ACT
    generated_prompts = await prompt_generator.generate_prompts()

    # ASSERT
    mock_invoker.assert_called_once()
    assert isinstance(generated_prompts, dict)
    assert len(generated_prompts) > 0

    first_piece_prompts = generated_prompts["The Heritage Drape Blazer"]
    final_garment_prompt = first_piece_prompts["final_garment"]

    assert DEFAULT_STYLE_GUIDE.art_direction in final_garment_prompt
    assert "The Heritage Drape Blazer" in final_garment_prompt
    assert (
        f"Avoid {DEFAULT_STYLE_GUIDE.negative_style_keywords}" in final_garment_prompt
    )
