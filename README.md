# Creative Catalyst Engine

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/your-username/creative-catalyst-engine)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

The **Creative Catalyst Engine** is an AI-powered, idea-to-image pipeline, delivered as a scalable web service. It turns a simple creative brief into a multi-format fashion intelligence package: a structured trend report (JSON), art-directed narrative prompts, and final, editorial-quality images generated by DALL-E 3.

Built on an asynchronous architecture with a background job queue, the engine is designed for resilience, scalability, and seamless integration into larger creative workflows.

---

## Table of Contents

- [Creative Catalyst Engine](#creative-catalyst-engine)
  - [Table of Contents](#table-of-contents)
  - [Key Features](#key-features)
  - [Architecture Overview](#architecture-overview)
  - [Repository Structure](#repository-structure)
  - [Setup](#setup)
    - [1) Prerequisites](#1-prerequisites)
    - [2) Clone](#2-clone)
    - [3) Create a Virtual Environment](#3-create-a-virtual-environment)
    - [4) Install Dependencies](#4-install-dependencies)
    - [5) Environment Variables](#5-environment-variables)
  - [Running the Engine](#running-the-engine)
    - [Step 1: Start Docker \& Redis](#step-1-start-docker--redis)
    - [Step 2: Start the Celery Worker](#step-2-start-the-celery-worker)
    - [Step 3: Start the API Server](#step-3-start-the-api-server)
  - [Interacting with the API](#interacting-with-the-api)
  - [Outputs](#outputs)
  - [Troubleshooting](#troubleshooting)

---

## Key Features

*   **Asynchronous & Scalable API**
    A FastAPI front-end accepts jobs instantly and queues them for background processing with Celery and Redis, ensuring a fast, non-blocking user experience.

*   **End-to-End Image Generation**
    The pipeline doesn't just stop at prompts; it executes them with DALL-E 3 to produce final, high-quality, editorial-style images.

*   **AI Creative Direction**
    A unique, intermediate AI step translates the abstract brand ethos into a concrete photographic style guide, providing expert-level art direction for lighting, mood, and model persona.

*   **Deep Ethos Analysis**
    Goes beyond keywords to understand the user's core philosophy, using it as a guiding principle for the entire creative process.

*   **Robust Synthesis Engine**
    A "Divide-and-Conquer" synthesis process, hardened with constraint-driven prompts, ensures the generation of logically sound, validated, and highly detailed JSON reports.

*   **L1 Report Caching**
    A ChromaDB-backed semantic cache makes re-runs of similar briefs near-instant, saving significant time and API costs.

---

## Architecture Overview

The engine is architected as a modern, decoupled web service for scalability and resilience.

```
+--------+      (1. POST /jobs)      +----------------+      (2. Enqueue Job)      +-----------------+
| Client | ------------------------> |   API Server   | ------------------------> |    Job Queue    |
|        | <------------------------ |   (FastAPI)    |                           | (Redis)         |
+--------+   (6. GET /jobs/{id})     +----------------+      (3. Dequeue Job)      +--------+--------+
    ^                                                                                       |
    | (7. Return Final JSON & Image URLs)                                                   v
    |                                                                            +-----------------+
    |                                                                            | Background      |
    |                                                                            | Worker (Celery) |
    |                                                                            | - Runs Catalyst |
    |                                                                            |   Pipeline      |
    |                                                                            +--------+--------+
    |                                                                                       | (4. Generate Image)
    |                                                                                       v
    |                                                                            +-----------------+
    |                                                                            |   DALL-E 3 API  |
    +----------------------------------------------------------------------------+--------+--------+
                                                                                          | (5. Upload Image)
                                                                                          v
                                                                                   +-----------------+
                                                                                   | Cloud Storage   |
                                                                                   | (S3 / GCS)      |
                                                                                   +-----------------+
```

---

## Repository Structure
```
creative-catalyst-engine/
├── .env                     # Your API keys and secrets (not committed to Git)
├── README.md                # The main project documentation file
├── requirements.txt         # A list of all Python dependencies for the project
├── sources.yaml             # Optional: Expert sources to guide the AI's research
├── clear_cache.py           # A utility script to purge the ChromaDB cache
│
├── api/                     # Handles the web service, job queueing, and workers
│   ├── __init__.py
│   ├── main.py              # The FastAPI application, defines API endpoints
│   ├── worker.py            # Defines the Celery application and the background tasks
│   └── eventlet_worker.py   # A safe entry point for starting the worker on macOS
│
└── catalyst/                # The core creative generation library
    ├── __init__.py
    ├── main.py              # A reusable library function and a script for local testing
    ├── settings.py          # Central configuration for the application
    ├── context.py           # Defines the RunContext data object for the pipeline
    │
    ├── clients/             # Manages communication with external APIs
    │   ├── __init__.py
    │   └── gemini_client.py # A resilient client for all Google Gemini API calls
    │
    ├── models/              # Contains the Pydantic data models for validation
    │   ├── __init__.py
    │   └── trend_report.py  # Defines the structure of the FashionTrendReport
    │
    ├── prompts/             # A library of all master prompt templates
    │   ├── __init__.py
    │   └── prompt_library.py
    │
    ├── caching/             # Manages the L1 semantic cache
    │   ├── __init__.py
    │   ├── cache_manager.py # A high-level facade for interacting with the cache
    │   └── report_cache.py  # The low-level ChromaDB implementation
    │
    ├── utilities/           # Helper modules for logging and configuration
    │   ├── __init__.py
    │   ├── config_loader.py # Loads and formats the sources.yaml file
    │   └── logger.py        # Configures the structured JSON logger
    │
    └── pipeline/            # The core orchestration and processing logic
        ├── __init__.py
        ├── base_processor.py# Defines the abstract base class for a pipeline step
        ├── orchestrator.py  # The main PipelineOrchestrator that runs the steps
        │
        └── processors/      # Contains all the individual pipeline steps
            ├── __init__.py
            ├── briefing.py  # BriefDeconstruction, EthosClarification, BriefEnrichment
            ├── synthesis.py # WebResearch, ContextStructuring, ReportSynthesis, Fallback
            ├── reporting.py # FinalOutputGenerator (JSONs and Creative Direction)
            └── generation.py# DalleImageGenerationProcessor (DALL-E 3 image creation)
```
---

## Setup

### 1) Prerequisites

*   **Python 3.11+**
*   **Docker Desktop:** The application uses a Docker container to run its Redis message broker. [Install Docker Desktop](https://www.docker.com/products/docker-desktop/).

### 2) Clone

```bash
git clone https://github.com/your-username/creative-catalyst-engine.git
cd creative-catalyst-engine
```

### 3) Create a Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 4) Install Dependencies

```bash
pip install -r requirements.txt
```

### 5) Environment Variables

Create a `.env` file in the repo root:

```
GEMINI_API_KEY="your_gemini_api_key_here"
DALLE_API_KEY="your_openai_api_key_here"
```

---

## Running the Engine

The application is a multi-part system. You will need **3 separate terminal windows** running simultaneously.

### Step 1: Start Docker & Redis

First, ensure Docker Desktop is running. Then, start the Redis container.

```bash
# This command only needs to be run once. It will download and start Redis.
docker run -d -p 6379:6379 --name creative-catalyst-redis redis

# On subsequent days, just start the existing container:
docker start creative-catalyst-redis
```

### Step 2: Start the Celery Worker

Open a new terminal, activate your virtual environment (`source venv/bin/activate`), and start the worker.

```bash
# For Linux or Windows Subsystem for Linux (WSL)
celery -A api.worker.celery_app worker --loglevel=info

# CRITICAL: For macOS users (to prevent common errors)
celery -A api.eventlet_worker.celery_app worker --loglevel=info -P eventlet
```
> **Note:** Leave this terminal window open. It will show the live progress of your creative jobs.

### Step 3: Start the API Server

Open a third terminal, activate your virtual environment, and start the API server.

```bash
uvicorn api.main:app --reload
```
> The server will be running at `http://127.0.0.1:8000`.

---

## Interacting with the API

The easiest way to interact with the API is through the built-in documentation.

1.  Open your web browser and navigate to **`http://127.0.0.1:8000/docs`**.
2.  Expand the **`POST /v1/creative-jobs`** endpoint.
3.  Click **"Try it out"**, enter your creative brief in the request body, and click **"Execute"**.
4.  You will instantly receive a `job_id`.
5.  Expand the **`GET /v1/creative-jobs/{job_id}`** endpoint, click **"Try it out"**, and paste your `job_id` to check the status. When the job is complete, the final JSON report will be displayed.

---

## Outputs

On each run, the engine creates an AI-summarized, timestamped folder under `./results/`. Inside, you will find:

*   `itemized_fashion_trends.json` — The validated `FashionTrendReport`.
*   `generated_prompts.json` — The structured narrative prompts.
*   **`[garment-name].png`** — The final, DALL-E 3 generated images for each key piece.
*   `debug_run_artifacts.json` — A complete log of all data from the run.

---

## Troubleshooting

*   **Celery Worker Fails on macOS:** macOS has known issues with Celery's default process pool. The solution is to use the `eventlet` pool as specified in the run commands. This requires the `api/eventlet_worker.py` entry point to ensure necessary patches are applied at startup. If you still encounter errors, ensure you are using the exact command provided.

*   **`ModuleNotFoundError` from Worker:** This usually means the worker process can't find your `catalyst` library. The latest version of `api/worker.py` solves this by adding the project path to `sys.path` *inside the task*. Ensure your code reflects this "lazy import" pattern.